# promptfoo configuration for GitLyte prompt evaluation
# Run with: npx promptfoo eval

description: GitLyte Prompt Evaluation Suite

# Prompt files to test
prompts:
  - file://prompts/repository-analysis.txt
  - file://prompts/design-generation.txt
  - file://prompts/content-generation.txt

# AI providers to test against
providers:
  - id: anthropic:claude-sonnet-4-20250514
    config:
      temperature: 0.3
  - id: openai:gpt-4o
    config:
      temperature: 0.3

# Test cases for repository analysis
tests:
  # Test case 1: CLI tool repository
  - vars:
      repo_name: "fastcli"
      repo_description: "A blazing fast CLI tool for file operations"
      repo_language: "Rust"
      repo_topics: "cli, rust, performance, files"
      readme_excerpt: |
        # fastcli
        Fast file operations from the command line.
        ## Features
        - Copy files 10x faster
        - Parallel processing
        - Progress bars
    assert:
      - type: contains
        value: "cli"
      - type: llm-rubric
        value: "The response should identify this as a CLI tool targeting developers"
      - type: is-json

  # Test case 2: Web framework repository
  - vars:
      repo_name: "quickweb"
      repo_description: "Lightweight web framework for Node.js"
      repo_language: "TypeScript"
      repo_topics: "web, framework, nodejs, typescript"
      readme_excerpt: |
        # QuickWeb
        Build web apps in minutes.
        ## Quick Start
        ```js
        const app = quickweb();
        app.get('/', () => 'Hello World');
        app.listen(3000);
        ```
    assert:
      - type: contains
        value: "framework"
      - type: llm-rubric
        value: "The response should identify this as a web framework for developers"
      - type: is-json

  # Test case 3: Data science library
  - vars:
      repo_name: "dataflow"
      repo_description: "Data pipeline library for Python"
      repo_language: "Python"
      repo_topics: "data, python, pipeline, etl"
      readme_excerpt: |
        # DataFlow
        Build data pipelines with ease.
        ## Installation
        pip install dataflow
    assert:
      - type: contains
        value: "data"
      - type: llm-rubric
        value: "The response should identify this as a data/ML library"
      - type: is-json

# Output configuration
outputPath: ./eval-results/promptfoo-results.json

# Evaluation settings
evaluateOptions:
  maxConcurrency: 2
  showProgressBar: true
